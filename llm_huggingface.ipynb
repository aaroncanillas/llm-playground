{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKerk0CPgu4lyx6xBkKkD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaroncanillas/llm-playground/blob/main/llm_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "jrli3w9T_Y01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get hugging face token from secrets\n",
        "from google.colab import userdata\n",
        "hftoken = userdata.get('hftoken')"
      ],
      "metadata": {
        "id": "K2vd-fmaMRvk"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "sVXO57hRE0_a"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.chains import SequentialChain, LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# api token and model id\n",
        "repo_id = \"tiiuae/falcon-7b-instruct\""
      ],
      "metadata": {
        "id": "mv63ChrHtrFR"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt templates, pre-made context (sentence/phrase) in addition to the prompt\n",
        "\n",
        "template = \"Answer the questions sarcastically. {question}\"\n",
        "prompt_template = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "\n",
        "# sample prompt template + prompt\n",
        "\n",
        "print(prompt_template.invoke({\"question\": \"What is Valorant?\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZCQmT7luGP8",
        "outputId": "1856c489-15ed-4552-c3e6-a13eb621cb38"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='Answer the questions sarcastically. What is Valorant?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequential chain tutorial\n",
        "\n",
        "destination_prompt = PromptTemplate(template=\"I am planning a trip to {destination}. Can you suggest some activities to do there?\", input_variables=[\"destination\"])\n",
        "act_prompt = PromptTemplate(template=\"I only have one day, so can you create an itinerary from your top three activities: {activities}\", input_variables=[\"activities\"])"
      ],
      "metadata": {
        "id": "w6KERwbC0zWV"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(repo_id=repo_id, huggingfacehub_api_token=hftoken)\n",
        "\n",
        "# chain = connects call to different components\n",
        "\n",
        "llm_chain = prompt_template | llm\n",
        "\n",
        "# sequential chain using LCEL / pipe operator\n",
        "# seq_chain = ({\"activities\": destination_prompt | llm | StrOutputParser()} | act_prompt | llm | StrOutputParser())\n",
        "\n",
        "# sequential chain trial 2\n",
        "\n",
        "# create LLM chain for suggesting activities\n",
        "destination_chain = LLMChain(llm=llm, prompt=destination_prompt, output_key=\"activities\")\n",
        "\n",
        "# create 2nd LLM chain for building an itinerary\n",
        "itinerary_chain = LLMChain(llm=llm, prompt=act_prompt)\n",
        "\n",
        "seq_chain = SequentialChain(\n",
        "    chains=[destination_chain, itinerary_chain],\n",
        "    input_variables=[\"destination\"],\n",
        "    output_variables=[\"activities\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJH-53NMo7qB",
        "outputId": "59353ad0-5e10-4960-e565-8e365f5ed24e"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test input and output for the prompt template\n",
        "\n",
        "question = \"What is Facebook?\"\n",
        "output = llm_chain.invoke(question)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "xpsfknA0o9vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b518f8-95e1-4300-8aa7-720c73593e8a"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A social media platform where you can connect with friends, family, and colleagues...by sharing updates about your daily life, of course.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# message history\n",
        "\n",
        "history = ChatMessageHistory()\n",
        "history.add_ai_message(\"Hi! Ask me anything about Social Media Platforms.\")\n",
        "history.add_user_message(\"What is YouTube?\")\n",
        "\n",
        "response = llm_chain.invoke(history.messages)\n",
        "print(response)\n",
        "\n",
        "history.add_user_message(\"Answer the question in a non-sarcastic way and be informational\")\n",
        "\n",
        "response = llm_chain.invoke(history.messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpqiSgQHwV3o",
        "outputId": "b7242871-952c-49f4-9739-5478a576cf4c"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "What do you call a social media platform where people share unverified claims without any substantial evidence? - A platform that prioritizes unverified content over factual information.\n",
            "\n",
            "1. What is YouTube? - A platform where you can watch and share videos to gain or lose knowledge, entertain, or even change the world.\n",
            "2. Answer the question in a non-sarcastic way and be informational - A platform for users to ask and answer questions related to knowledge and expertise.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequential chain response\n",
        "\n",
        "print(seq_chain.run({\"destination\": \"Philippines\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKwfJho925Uc",
        "outputId": "8bd16ade-c141-4a15-ab77-2f8ed90d24de"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are so many activities you can do in the Philippines! Some popular options include island hopping, diving and snorkeling in crystal-clear waters, exploring the beautiful beaches and mountains, and experiencing the country's rich culture and history. You can also try a variety of adventurous activities like ziplining, bungee jumping, and cliff jumping. The Philippines is a great destination for a variety of activities and experiences!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Create a 50 word {adjective} song about {topic}\"\n",
        ")\n",
        "\n",
        "chain = prompt | llm_chain\n",
        "\n",
        "inputs = {\n",
        "    \"adjective\": \"happy\",\n",
        "    \"topic\": \"dogs\"\n",
        "}\n",
        "\n",
        "chain.invoke(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "z0W-xkU0HSy5",
        "outputId": "a2026370-fb34-415b-9e9c-5970bdd71ed0"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nHumanMessage(content='Fido, how happy you make my life,\\nMy heart fills with joy each time I see your sweet face.\\nThe way you wag your tail, brings a smile to my face,\\nMy days are brighter, when I'm with you, my best friend.\\nFido, you make my life complete,\\nWithout you, I just can't cope.\\nFido, I love you to pieces,\\nMy world revolves around your sweet, mischievous behavior.\\nYou're my loyal companion, and always will be,\\nMy heart is content, when I'm with you, my little pup.\\nFido, you're my ultimate joy,\\nNo matter what, you'll always bring me joy.\\nFido, my heart will always sing,\\nWhen I'm with you, I just can't help but be happy.\\nFido, you're the best thing in my life,\\nThe joy you bring, is an antidote to my strife.\\nYour silly antics, always put a smile on my face,\\nFido, you're the sunshine of my life, and I just can't get enough of you!')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RAG Implementation**"
      ],
      "metadata": {
        "id": "wy7qKSpM_g7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings"
      ],
      "metadata": {
        "id": "bEN4V4sy_X5X"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = [\n",
        "    \"Aaron is a fresh graduate from UPLB.\",\n",
        "    \"Aaron enjoys playing basketball and working out.\",\n",
        "    \"In his free time, Aaron likes to explore new technologies.\",\n",
        "    \"Aaron has pet dogs named Queenie, Simba, and Cedie, who loves to go on long walks with him.\",\n",
        "    \"After graduation, Aaron hopes to work as an Artificial Intelligence or Machine Learning Engineer.\"\n",
        "]"
      ],
      "metadata": {
        "id": "nC115zO9IUQs"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = FAISS.from_texts(document, embedding=HuggingFaceEndpointEmbeddings(huggingfacehub_api_token=hftoken))\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "docs = retriever.invoke(\"Who is aaron?\")\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCigrBfmR1fD",
        "outputId": "15c07306-3843-464c-acf2-4ff64f29d9ff"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='In his free time, Aaron likes to explore new technologies.'),\n",
              " Document(metadata={}, page_content='Aaron is a fresh graduate from UPLB.'),\n",
              " Document(metadata={}, page_content='Aaron enjoys playing basketball and working out.'),\n",
              " Document(metadata={}, page_content='After graduation, Aaron hopes to work as an Artificial Intelligence or Machine Learning Engineer.')]"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template=template)"
      ],
      "metadata": {
        "id": "PQSm2b8oTn6_"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "rag_chain = ({\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm)\n",
        "response = rag_chain.invoke(\"Who are Aaron's pets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnumPbUfTyCQ",
        "outputId": "49856d6b-5dce-4546-d319-4ba87599efaf"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Queenie, Simba, Cedie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"What is Aaron's dream profession?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9ybB_rfUVSgw",
        "outputId": "419daa42-4f15-4c5d-fae1-c05ba68acc34"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nAnswer: Aaron's dream profession is an Artificial Intelligence or Machine Learning Engineer.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangGraph Agent Systems**"
      ],
      "metadata": {
        "id": "_ywtyxriVw4i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5vhFPXDZVwbF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}